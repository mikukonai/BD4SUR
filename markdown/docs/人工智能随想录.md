
#!title:    人工智能随想录
#!date:     2018-12-09
#!authors:  BD4SUR
#!cover:    
#!type:     原创
#!tags:     

#!content

> : **A**rtificial **I**diot
人 工 智 障

# AI产品化

## 能抓到耗子就是好猫

> 2018.11.1，朋友圈

前段时间我爸妈来南京住了一段时间，跟他们说这个小爱同学厉害的很，他们觉得一个音箱而已这么贵还没什么用。

后来每天都“小爱同学”“小爱同学”地叫她，扫地机器人自然不必说，就连晚上睡觉关灯都懒得用遥控器了。真香。

算下来，我在小米生态链上投入了大概不到一个月的工资，但是对生活质量的提升是成倍的。

我不想将这称为“人工智能”，这与真正的“智能”关系并不大。不过从另一个角度看，仅仅是简单的控制论“智能”（**其实就是家居自动化**），就足以颠覆式地改变人们的生活习惯，这就足以说明许多问题了。

## 零散的想法

- 学会训练用户，不能完全被用户牵着鼻子走：
-- 管理客户预期（由差变好易，由好变差难）
-- 引导客户行为（但是也不要有太强的侵入感）
-- 回应用户关切（交互要有反馈）
-- 跟踪用户重点（有取有舍，有所为有所不为）
- 相应地，不要制造人与机器的对立，而应是合作关系。
- AI是人类的代具，不是谁取代谁的对立关系，而是相互依存共同进化的关系。
- 目前的AI研究与其说是打移动靶，不如说根本就没有靶。（2020-12-08）

- 重视（广义的）交互设计。
- 重视面向人类的那一部分，即人机接口。

- 广义的二八原则和长尾现象：是否要追求完备？
-- 区别对待头部和尾部，数据、用户、场景，等等；
-- 两点论和重点论。

- 图灵测试是否合理？标准并不清晰。不是一个良定义的、量化的标准。
- 关于问答系统如何评价，学界和产业界都不太清楚。然而这很可能是一个教育学或者心理学问题。

- 技术不是大头，但技术是核心。

- 关于冷启动问题：
-- 于开发者，不要排斥规则和简单技巧，先让业务跑起来，再谈迭代演进。不能一口吃个胖子。
-- 于用户……？

- 训练一个人类幼崽到初中毕业的水平尚且要十五年，人工智能的迭代也不可以心急。



# NLP

## 语言模型应当是开放系统

> 首次发表于朋友圈，时间2019年3月3日，缘起是“微信翻译将一些当红艺人的英文名翻译成奇怪的东西”的新闻。

语言的演化是非常快的，但庆幸的是语言底层的演化要远远慢于表面。

刚才看晋语（汾阳话）教程时，发现汾阳话同样存在地名白读稳定的现象。白读反映语言内核，是可以传承的稳定的内核。但是作为一种世界观的再现，语言的演化和这个世界的变化是同步的。

好的语言模型可以学习到语言的底层内核，但是目前来看，它很难增量式地、有选择地学习到语言表面不断变化的那部分。这是一个很深刻的问题——因为人类**知道**哪些是内核，哪些是新概念、新说法、新流行语。

语言模型不仅仅是关于语言的模型，更是关于这个世界的一整套观念。目前训练出的语言模型本质上都是复读机，它们并没有像人类这样的，站在更高层次上理解语言、观察世界的能力。

最后我还是要复读一遍维特根斯坦的话：世界的意义，必定在世界之外。所以，语言模型无法处理的问题，就请交给规则去处理吧。

**神经网络适合从海量语料中挖掘语言的底层模式，而规则和逻辑更适合增量式地、后验地完善和修正现有的语言模型。**

补充一句：一个人能看懂网络上流行的梗、段子、亚文化，背后的代价一定是每天花几个小时刷微博或者抖音这类东西。语言模型为了能够覆盖到这些边边角角的新东西，就必须与人类一起学习，与社会一同进步，与世界同频共振。所以，从唯物辩证法的角度来看，不可能有一旦训练好就一劳永逸的语言模型，只有根据需求和成本考虑做出的取舍而已。

因此，**语言模型的最终形态必然是自适应、自学习、自组织、互联互通的开放系统。**

2020年7月12日补充：**强化学习**是机器学习的未来。

## 处理NLP问题时要考虑到目标语言的特性

具体语言的性质和模型的架构要综合考虑。例如日语等黏着语，更依赖词缀而不是语序来表达不同的语义，而汉语和英语则正好相反。屈折语更是在词的粒度上就携带了大量语法信息。所以，模型架构的设计，要具体语言具体分析。当然，由于汉语和英语在语法上的相似性（英语正在朝着简化、分析化的方向发展），产业应用时可能未必需要考虑那么多、那么细。

## 关于背景知识和言外之意

- 还有人说投资4.8万就可以移民台湾，天底下哪有这样的好事！
- 美国才是这个时代最大的恶棍。
- 多党轮流执政照样腐败。

## 零散的想法

- 数据存储→数据挖掘→知识工程→知识服务

- 所谓的语义理解可认为是广义的编译过程。自然语言→语义
- “语义”是个非常玄学的东西。现在所知的语义表示有：
-- 自然语言表示（隐式）
-- 形式语言表示（显式、结构化的）
--- 字符串模式
--- 一阶逻辑
--- λ演算（形式语义）
--- 结构化语言（槽）
--- 树、图模型
--- 类别（指称语义？，与分布式表示紧密相关）
-- 分布式表示（隐式）
--- 神经网络
--- 向量空间嵌入
--- 语言模型（概率图模型等）
- 上面这些表示可以互相转化。
- 语义学是一个学科，有许多研究角度。
- 语义和“知识”有什么关系？
- 语义里面还有情感等主观因素。
- 情感是非常微妙的，可以认为是高阶的语义。从AI落地的角度来说，如果脱离应用场景，很难对情感建模。或者，其实也没必要，简单分类足以解决大部分问题。
- 语义必须放在上下文的“闭包”中才有可以解释的意思。
- 例如：中国人的“意思”。

![没别的意思（图片来源见水印）](./image/G5/yisi.jpg)

- 6W2H：what、when、where、who、why、which、how、howmany/much。
- 实现时，首先需要约定“语义”的表示，这是NLU接口的一部分。
- 很难搞清楚NLU这个编译器的输入输出。
- 其实人类也在探索自己是如何思考的。
- 人脑内的知识是分布式表示的。从分布式表示→逻辑是如何跨越的？
- 研究AI就是研究人类自己。

# CV

# 语音

# 参考资料

+ 题图来源：pixiv#70385021


