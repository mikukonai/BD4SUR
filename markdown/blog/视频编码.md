
#!title:    视频编码
#!date:     2019-08-04
#!authors:  BD4SUR
#!cover:    ./image/cover/hibike-ed1.jpg
#!type:     原创
#!tags:     视频

#!content

# 〇 视觉技术体系

- 采集·感知：成像和摄影 / HVS / 光学 / 光机电系统
- 处理·通信：图像处理 / [[#ff0000:**高效编解码**#]] / 视频通信广播 / 存储 / 版权
- 建模·认知：计算机图形学 / AR/VR / 计算机视觉 / 语义化和信息检索
- 呈现·交互：显示和打印 / 图形计算 / Web前端/GUI / 人机交互 / 字体排印

# 一 绪言

**1-1 研究动机**

- **时代背景** 毫无疑问，视觉是人类最重要的知觉。2020年的新冠疫情，网络摄像头价格飞涨，远程教育大发横财，远程办公迅速普及，让人们意识到音视频通信或许是下一个刚需。至于之前一直不瘟不火的AR/VR、4K~8K超高清、全景直播，乘着5G的东风也开始有了复兴的迹象。虽然影院KTV尚未复工复业，但红米的98寸大电视、B站大会员的4K视频也让人直呼真香。大片永远嫌不够多，大电视永远嫌不够大。底大一级压死人，如今依然是至理名言。
- **技术难题** 视频号称“最大的大数据”，其巨大的数据量是一切技术难题的万恶之源。因此，**高效**视频编解码，在整个视觉技术体系中作为底层基础，地位相当重要，是学界、业界重点关照的领域。视频编码和视频理解被业内公认为最有挑战性的两个领域。在这两方面，无论是技术研究还是产业落地，我国做得都还不错，至少不算落后。
- **技术自主** 视频编码地位重要、技术难度大、专利和标准壁垒高、先发优势效应明显，堪称视觉技术领域的光刻机，是**要不来、买不来、讨不来、也很难通过市场调节自发创造出来**的核心卡脖子技术。好在二十年前的DVD专利案给了国人当头一棒，如今才有了渐入佳境的AVS标准。还是那句话，我可以不用，但你不能没有。对于一个有抱负的国家来说，核心技术这块儿必须做到自主可控，没有任何捷径和退路。
- **个人兴趣** 个人知识管理需要维护大量的动画、电影等视频文件，涉及压制、转码、后处理、甚至检索等工作，有必要了解视频编解码的原理。另一方面一直对音视频技术感兴趣，因此愿意深入钻研下去。

**1-2 研究目标**

- 总的来说是抱着玩票的态度去研究。当然，以后靠这个吃饭也是说不定的事情。无论如何，满足自己的兴趣是首要目的。
- 输出一些有价值的材料，包括学习笔记、图表、文献综述等等，一方面是将自己学到的东西沉淀下来，另一方面有助于后来者入门。
- 写一些代码，知行合一。
- 掌握ffmpeg的用法。

**1-3 研究方法**

- **文献调研** 文献调研是研究工作的起点和重点，其目的是梳理本领域的概念体系、发展历程、经典文献、方家巨擘，以便后续可以纲举目张地进行深入研究。文献调研总的来说是个自举的过程，触发自举的源头有维基百科词条、知乎大佬文章、高校课程讲义、以及随缘看到的公号文章、业界资讯、博客笔记等等。从这些源头出发，通过引用关系递归地爬取文献资料，初步建立起能够反映本领域全貌的文献集合。当然，这个过程需要有选择地爬取价值较高、有代表性的材料，时刻注意去粗取精，不能无脑爬取而徒增负担。还需要注意的是，材料之间既要相互覆盖，又要尽可能从不同的角度去论述问题。不同材料之间相互对照，有助于去伪存真、获得相对可靠的知识。另外，为了保证参考资料随时可考，所有材料都必须保留自有备份。
- **输出驱动** 以输出倒逼输入，在创作中发现问题。
- **多提问题** 一个好的问题，胜过一百个现成的知识。
- **知行合一** 多写代码。需要遵守“代码即文档”的选择，保证可读性第一。

**1-4 结构和内容** 本文从视频编码的基本原理出发，展开介绍主流标准所使用的三大核心工具——变换、预测和熵编码，以及率失真优化等关键技术。随后分析主流视频编码标准，包括MPEG系、ITU系和AVS系，按照时间顺序分成三代，重点放在横向纵向比较，勾勒出视频编码标准的进化脉络。最后回归实践，介绍FFmpeg的使用方法。

## 6月12日写的短文

从0101二进制串→位图的过程，各位已经讲得很清楚了。我主要补充一点有关图像/视频压缩的东西。

如果没有视频压缩，那么很容易计算出，一个时长为1分钟、帧率25fps、分辨率为1920×1080逐行、每个像素RGB共24bit的简单视频，它的尺寸大约是9.3GB。然而实际见到的这类视频一般只有几MB～几十MB左右，这意味着编码器可以将原始视频以成百上千倍的效率对视频进行压缩，大大节约硬盘容量和带宽。以下是视频压缩的基本原理。

首先要知道，由于视网膜上感受亮度的杆细胞远多于感受色彩的锥细胞，因此人眼对亮度的感觉比色度更敏感。根据色彩理论，RGB并非表示颜色的唯一方式，还有一种方式称为YUV。出于以下的优势，图像/视频编码一般使用YUV表示。

Y指亮度分量，可以理解成黑白电视信号。而UV指两个色度分量。因此用YUV方式传输视频信号，可以非常方便地实现黑白电视与彩色电视的兼容。

更重要的是，人眼对Y比UV更敏感，因此可以在不损失画质的前提下，适当减少UV成分。普通的RGB图像中，RGB是同样多的，但是对于YUV来说，U和V的数量可以减半（指宽度或高度方向上），称为YUV422排列或者YUV420等等。

除了人眼生理特点决定的色彩冗余之外，视频内容本身也存在大量冗余。包括时空冗余、频域冗余、编码冗余等等。以下开始逐个消除这些冗余。

静止图像有大量的空间冗余。对于类似于框图、图书扫描的那种图像，它的背景有大片的空白，这部分空白内容就可以通过各种手段压缩掉。例如游程编码、例如帧内预测等等。

视频在时间上同样有更大的冗余。例如监控探头拍摄的画面，如果画面中没有物体运动，那么连续多帧画面之间的差异是很小的。此时，只需要编码传输第一帧（关键帧）和后面各帧与它的差异就可以了。如果画面中有物体运动，也是同样的思路，只需要编码传输画面中运动部分的位移信息即可。通过这种手段，可以消除掉绝大多数冗余。

以上两种压缩编码方法利用了视频在时空两个维度上的冗余，统称为预测编码。

还有一种重要的编码手段称为变换编码，用于消除图像的频域冗余。因为人眼对于图像中细微波动的细节并不敏感，所以可以想办法在人眼可接受的前提下，将一部分细节去除掉。方法是通过离散余弦变换（DCT）将直观上按照像素的空间位置排列的图像，转换为按照空间频率排列的频谱图。频谱图的特点是绝大多数信息都集中在一个角落里，而远离这些角落的零散信息，就是人眼难以感知到的冗余。

这一阶段的压缩效率如何呢？比如说对于一个8×8的原始图像，变换前需要保存所有64个像素，但变换后可能只剩下角落里的10个点比较重要（强度比较大），其余54个点都是可以被丢弃的冗余信息，因此只保留那10个重要的点就可以了。保留下来的少数几个点，再经过量化，可以简单理解成四舍五入，使这些频率点变成有限的几个值，实现更进一步的压缩。（注：实际上保留或者丢弃的操作是通过调整量化参数实现的，因为过小的值经过量化后就变成0没有了，相当于被丢弃掉了。）

变换编码/量化之后，还有一种强大的编码手段——熵编码。由于量化得到的值其取值范围是有限的，因此每个值（或多个值构成的元组）都可以看成是一个符号。熵编码的核心思想是根据原始信息中符号的概率分布，设计最佳的编码本，使得出现概率越大的符号编码越短，出现概率越小的符号编码越长。比如26个英文字母里A出现的概率远高于Z，因此A的编码长度要短于Z，才能保证总体编码长度较短。JPEG采用较为简单的哈夫曼编码，它的编码本是固定的。而H.264等视频编码标准采用更灵活的CABAC（上下文自适应算术编码）等方法，它会实时统计各个符号的出现概率，同时更新编码本，达到更高的压缩效率。

最后，为了保证视频信号不出错不失真，还会引入很多抗误码手段，例如校验码、例如灵活宏块排序等等，保证万一数据出错，要么可以通过校验码恢复，要么不会影响到太大的范围。

经过以上各种方法的处理，简单的二进制表示的图像，可以被压缩到原来尺寸的几百乃至上千分之一。无论是放在硬盘上慢慢欣赏，还是用4G流量看实时直播，都毫无压力了。

以上便是图像/视频压缩的大致原理。

## 6月19日笔记

在《数字图像压缩编码》这本书中，用比较短的篇幅讲清楚了 ITU-T（VCEG）和 ISO/IEC（MPEG）两大门派制订视频编码标准的不同考虑。

ITU-T侧重“视频通信”，对于压缩效率、Codec成本和速度、在不可靠信道上如何靠谱地传输这类问题考虑得多一点。同时比较重视标准的体系化，试图将音视频通信嵌入到 ITU-T 的整个建议书体系中。

MPEG侧重“多媒体应用”，每一代标准都试图建立完整的多媒体应用系统的全套标准，相比于ITU-T，MPEG对于封装、交互、系统集成着墨较多。

- MPEG系标准是VCD/DVD/蓝光这类消费者产品的核心技术，正是其重应用思路的体现。
- ITU-T的G系列是重要的话音编码标准，H.261等标准至今仍在视频会议等场景应用广泛。
- MP3/AAC都是MPEG颠覆业界的杰作，但是这俩标准的理论编码延时都高得惊人，显然不是为了音频通信设计的。
- H.264提出的网络抽象层概念，就是为IP网上的视频通信设计的，充满了通信味儿。相比之下，MPEG从MPEG-1开始就引入了B帧，用术语来说就是非因果的，明摆着就是为了回放而不是实时通信设计的。
- MPEG-4非常超前非常大胆，它提出来的对象编码、视频交互、语义化等方向，即使在现在也很少可以完整实现。

## 6月20日笔记

B站的视频编码码率控制：

- 离线的码率失真优化
- 引入机器学习预测编码参数
- 内容分类/切分场景
- 控制复杂度和视频上线时间
- 根据用户行为触发更高级的优化

## 原型特性规划（6月24日）

- 基于YUV420，逐行。
- 不需要条带
- 仅I帧和P帧两种。
- 仅支持8×8的宏块，不支持子块分割。
- 浮点DCT。量化参数？
- 帧内模式5种，同AVS。
- 仅前向参考。如何选择参考帧？
- 运动估计暂且采用1像素精度。
- 简单的游程编码，熵编码先不做。
- 率失真优化：拉格朗日优化，或不做。
- 码率控制：待调研。​​​

## 20200520笔记

- 包括子块划分、帧内预测模式、参考帧、量化参数在内的编码模式的决策，一方面是RDO，另一方面是启发式的选择。（参考：知乎文章H.265概念解析[OL]、深入理解视频编解码技术[M]）
- 去块滤波有两类，一类是作为解码后处理的 post filter，另一类是位于编码环路内部的 loop filter. （深入[M] p139）
- 问：为什么帧内预测的输入信号（相邻参考块）不需要去块滤波？猜想：去块滤波是针对整幅图像的，而帧内预测只能基于（一般位于左、上两个已编码方向）已编码的MB（更一般地，分析单元）。
- 问：帧内预测是以已编码块的边界作为预测依据，也就是说当前块的RDO实际上与相邻的每个块的RDO都相关。新的编码标准中是否有考虑到这一点？答：好像是有的。不过就这个问题而言，性价比似乎不高。
- 框出编码器里面的解码器。

# 二 视频编码的基本原理

## 人类视觉特性

![颜色降采样，原因可能与锥细胞和杆细胞数量比例有关。\[@中国科普博览20190823微博\]](./image/G7/video-encoding/颜色降采样.jpg)

## 视频基础知识

![像素采样模式 \[B11\]](./image/G7/video-encoding/像素采样模式.png)

## 视频信息冗余

![信源编码示意图](./image/G7/video-encoding/信源编码.png)

上图中，信源编码器的任务是将信号分成两部分：一部分是有关信源性质的大量共性知识；另一部分是剥离掉这些共性知识的少量特性信息。对于感知编码而言，编码器还会有选择地去掉人类无法感知的信息。这样，信号就被分成了**共识**和**特征**两部分，其中“特征”部分的数据量远小于“共识”部分，这样就实现了数据的压缩。在信道上传输的，实际上是信号的“特征”；而“共识”部分，则通过标准和协议的形式，固化在每一个信源编解码器中。

例如，假设已经知道（约定）信源是一个标准的正弦波，那么只需要传输这个正弦波的相位、频率和幅度就足够了，不需要传输每一个采样点。再例如，假设已经知道（约定）信源是一个安防监控探头采集的图像，由于图像绝大多数时间都是固定不动的，因此只需要传输每帧之间的差异、或者画面中运动的内容就足够了。

作为信源编码的一类，视频编码就是从视频信号中剥离掉共性的知识，如时域/空域/频域相关性、编码的上下文特征、分形的纹理特征、特定的语义内容（如人脸、物体、几何形状）等，并（在可接受的前提下）抛弃掉人类难以感知的信息（如精细的色度信息、难以察觉的空域高频成分），只留下少量相关性很低的信息，实现视频信号的压缩。因此，视频编码，可以认为就是视频压缩。

信源编码分为**无损**和**有损**两类。有损编码会损失掉原信号的部分信息，解码后得到的信号并不完全等同于原信号，会有一定的失真。编码器的一个重要任务是，在失真可接受的前提下，尽可能提高数据压缩的效率；或者在数据率可接受的前提下，尽可能减小失真。这是一个带约束的优化问题，称为**码率-失真优化**（Rate-Distortion Optimization）问题。RDO实际上解决的是三方面问题

- 更好的失真度量方法
- 更高效的压缩编码
- 更好的RDO算法本身

信源编码，是对信号的内在性质、乃至这个世界的深刻再理解。

## 视频编解码框架

当今应用最广泛的视频编码框架，是基于预测-变换的混合式视频编码框架。它的特点如下：

- 总的来看是一个带反馈的差分预测编码框架
- 框架前向通路中引入了变换编码
- 残差信号经过量化、变换后，再进行熵编码
- 编码器包含完整的解码器

![差分脉冲编码调制（DPCM）框架](./image/G7/video-encoding/DPCM.png)

![视频编码器框图](./image/G7/video-encoding/video-encoder-arch.png)

![H.264的混合编码框架 \[B1\]](./image/G7/video-encoding/H264-framework.png)

## 编码工具和编码策略

## 编码性能评价

# 三 变换编码与量化

## 变换编码的理论基础

**x.1** 自然的空域图像信号往往有大片的平坦缓变区域，如蓝天、皮肤、白墙等等。也就是说，在图像的局部范围内，像素之间的差异是比较小的。

**x.1.1** 从频域的角度看，**x.1**意味着图像信号中直流和低频成分往往占据大部分能量。

**x.1.2** 从统计的角度看，**x.1**意味着图像信号的相近像素之间有较强的相关性。统计表明，像素间距离越近，相关性越强。

![灰度差值的概率分布 \[B7\]](./image/G7/video-encoding/灰度差值概率分布.png)

**x.2** 我们的目标是，在不损失过多信息的前提下，去除掉空域图像信号的冗余成分，实现信号的压缩。

**x.2.1** 从频域的角度看，根据**x.1.1**，我们可以设法去除能量较低的高频成分，保留能量较高的低频成分。

**x.2.2** 从统计的角度看，根据**x.1.2**，我们可以设法去除图像相近维度之间的相关性。

**x.3** 为了实现**x.2**所述的目标，我们可以通过某种变换，将图像的主要信息集中到少数维度上，这就是变换编码的核心思想。

**x.3.1** 为了实现**x.2.1**，可以将图像信号从空域变换到频域，将信号的能量集中到低频段，并去除高频段能量较少的成分，保留低频段能量较高的成分，达到数据压缩的目的。从1968年，人们[B6]首先使用FFT计算图像的频谱，但FFT是在复数上进行运算，显得有些冗余。后来人们提出了针对实信号的**离散余弦变换**（DCT），它本质上是FFT的导出形式，但是比FFT的能量集中性更好，并且同样具有快速算法。

![DCT比DFT有更好的能量集中性能 \[维基百科DCT词条\]](./image/G7/video-encoding/DFT-vs-DCT.jpg)

**x.3.2** 为了实现**x.2.2**，可以对图像向量作主成分分析，尽可能去除像素间的相关性（至少去除线性相关性），将图像信号降维到少数几个特征值上，达到数据压缩的目的。许多年(?)以前，人们提出**K-L变换**（Karhunen-Loève Transform，KLT），也叫**霍特林变换**（Hotelling Transform），它本质是一种正交线性变换，可以在均方误差最小的条件下实现随机信号的降维。但是，KLT的基底由图像的统计特征（如协方差矩阵）决定，计算复杂度较高且无快速算法，因而KLT只有理论上的意义，实用性很差，一般只用作性能比较的基准。（至于KLT和PCA的关系，可以认为PCA是KLT针对离散变量的特殊情况）

**x.4** 存在多种实用的变换算法，可以达到信号去相关的目的。变换算法需要满足几个特性：①可逆的正交变换；②性能近似KLT；③计算复杂度不能太高。

**x.4.1** 此类变换算法可分为正弦类变换和非正弦类变换。正弦类变换有FFT、DCT、离散正弦变换（DST）等，非正弦类变换有Haar小波变换、Walsh变换等。

**x.4.2** 非正弦类变换计算量较小，但效果较差，而且难以直观解释。正弦类变换尽管计算量较大，但是其效果更接近KLT，并且具有频率域变换的直观含义，因而成为主流的变换编码算法。

**x.5** DCT既是一种具有去相关特性的线性变换，也具有显然的频域分析的物理含义。尽管DCT去相关性能略输于KLT，但它①与输入图像无关，不需要计算输入图像的统计特征，且②有快速算法，并③具有易于理解的物理含义，实用性更强。不过，可以证明，当信号统计特性近似于一阶马尔可夫过程时，DCT的去相关性近似于KLT。

**x.5.1** 依据构造形式不同，DCT有8种变形，常用的是DCT-II，其反变换可以使用DCT-III计算得到。

**x.5.2** DCT具有快速算法，可实现$O(n \cdot \mathrm{log}(n))$的时间复杂度。一种是直接使用蝶形结进行递归分解，另一种是通过FFT来计算DCT。

**x.5.3** 二维图像信号的DCT可以通过两次一维DCT实现，即按行/列作一维DCT，再对变换结果按列/行作一维DCT。

**x.5.4** 近年来，随着算力的提升，自适应多核变换AMT[B3-p26]、基于在线训练的KLT[B8-p41]等更为复杂的变换算法被引入新一代的视频编码标准。音频信号由于涉及分帧和边界问题，使用经改进的DCT即MDCT实现变换编码。

**x.6** 理论上，DCT应针对整幅图像进行，以去除所有像素之间的相关性。但实际上都是先将图像分块，对每块单独计算DCT。这样做的原因是：①对整幅图作变换的计算量太大；②如果对整幅图作变换，变换编码传输中引入的误码在反变换后会分散到整幅图像，如果分块则会将误码局限在单个块内；③考虑到1所述的局部缓变性质，多数小块内的高频信息极少，因而对这类平坦小块单独计算DCT可以比对全图计算DCT更充分地去除掉冗余信息。（视频截图）

**x.6.1** 分块编码会导致块与块之间的边界不连续，形成可见的块边缘，这称为**块效应**。

**x.6.2** 根据图像内容自适应地选择块的大小和尺寸，不仅有利于减轻块效应，还有利于提高编码效率。

![更精细的宏块划分有助于提高编码效率 \[C1\]](./image/G7/video-encoding/宏块划分对比.jpg)

**x.7** DCT变换存在反变换（IDCT），变换后的信号经IDCT可以恢复出原始图像信号。但由于变换信号的高频冗余成分经后续的量化环节被压缩掉，恢复出的图像与原始图像并不完全一致，因而变换编码一般都是有损压缩编码。

## 离散余弦变换

$$ X[k] = \sum _{n=0} ^{N-1} {x[n] \cdot \mathrm{cos}( \frac{\pi}{N} k (n + \frac{1}{2}) )} $$

![8×8离散余弦变换的基模式 \[B11\]](./image/G7/video-encoding/DCT-basis-patterns.png)

![Zig-zag 排列方式 \[A2\]](./image/G7/video-encoding/zig-zag.png)

## H.264的整数变换

# 四 预测编码

## 4.1 帧内预测编码

## 4.2 帧间预测编码（20190807）

# 五 熵编码

- CAVLC
- CABAC

# 六 码率-失真优化（RDO）

# 七 视频编码标准

![视频编码标准简史 \[C3\]](./image/G7/video-encoding/history-of-video-coding.png)

![主流视频编码标准发展史 \[B5\]](./image/G7/video-encoding/Video-Encoding-History-2.png)

## 7.1 第一代标准

MPEG-1/2/4、H.261/2/3

## 7.2 第二代标准

H.264/AVC、AVS

## 7.3 新一代标准

H.265/HEVC、H.266/VVC、AVS2、AVS3

### HEVC的改进

### VVC的改进

- 块大小：128×128
- 更复杂的子块划分方式
- 67种亮度帧内预测模式
- 仿射运动矢量
- 自适应多核变换（AMT）

![图像分割方式的改进 \[C3\]](./image/G7/video-encoding/H266-piction-partitioning.jpg)

### AVS3的改进

# 八 视频编码的发展趋势

# 九 FFmpeg实践

## DVD或其他非AVC格式转码为HEVC

```
ffmpeg -i "INPUT" -vcodec libx265 -b:v <比特率> -preset ultrafast -acodec aac -b:a 256k "output.mkv"
```

**注意**：输出比特率按照以下规则设定：

- DVD：2000k
- 其他非AVC格式：与原始视频的比特率接近（或略低）。

除非有特殊需要，伴音一律压成256k的AAC。

## AVC转码为HEVC

## 视频合并

思路是先打包成可以直接合并的TS流，然后将合并后的TS转换成所需的封装格式。

```
ffmpeg -i 1.mp4 -vcodec copy -acodec copy -vbsf h264_mp4toannexb 1.ts
ffmpeg -i 2.mp4 -vcodec copy -acodec copy -vbsf h264_mp4toannexb 2.ts
ffmpeg -i "concat:1.ts|2.ts" -acodec copy -vcodec copy -absf aac_adtstoasc output.mp4
```

## 硬件Codec

# 参考资料

- 参考资料目录遵循 GB/T 7714-2005《文后参考文献著录规则》的要求编排。
- 如无说明，所有参考文献均有自有备份（纸质、电子文件或截图）。

**A.标准文档**

- A1 / **ITU-T H.264** 视听及多媒体系统/视听业务的基础设施/活动图像编码/通用视听业务的先进视频编码 [S]（H.264/AVC国际标准）
- A2 / **ITU T.81** [信息技术/连续色调静止图像的数字压缩和编码/要求和准则](https://www.w3.org/Graphics/JPEG/itu-t81.pdf) [S]（JPEG标准）
- A3 / **GB/T 33475.2-2016** 信息技术 高效多媒体编码 第2部分：视频 [S]（AVS2国家标准）

**B.论文、胶片、教材和专著**

- B1 / T Wiegand, G J Sullivan, G Bjontegaard, et al. **Overview of the H.264/AVC video coding standard**[J]. IEEE Transactions on Circuits & Systems for Video Technology, 2003, 13(7):560-576.
- B2 / 毕厚杰. **新一代视频压缩编码标准:H.264/AVC**[M]. 人民邮电出版社, 2005.
- B3 / G J Sullivan. **Versatile Video Coding – The Next-Generation Video Standard of the Joint Video Experts Team**[R]. 2018.
- B4 / 中科大《多媒体通信》课程讲义[R]
- B5 / 马思伟. **新一代AVS3视频编码标准**[R]. RTC2019.
- B6 / H C Andrews, W K Pratt. **Fourier transform coding of images**[?/找不到原始文章]. Hawaii International Conf. on System Sciences, pp. 677-679, 1968.
- B7 / 张春田, 苏育挺, 张静. **数字图像压缩编码**[M]. 清华大学出版社, 2006.
- B8 / 马思伟. **视频编码未来简史**[R]. RTC2017.
- B9 / 高文, 赵德斌, 马思伟. **数字视频编码技术原理（第二版）**[M]. 科学出版社, 2018.
- B10 / K R Rao, 金道年, 黄在静. **视频编码全角度详解**[M]. 机械工业出版社, 2017.
- B11 / I E Richardson. **The H.264 Advanced Video Compression Standard (second edition)**[M]. John Wiley & Sons, 2011.
- B12 / J Watkinson. **The MPEG Handbook (second edition)**[M]. Taylor & Francis, 2004.
- B13 / 陈靖, 刘京, 曹喜信. **深入理解视频编解码技术：基于H.264标准及参考模型**[M]. 北京航空航天大学出版社, 2012.

**C.视频、网课、博客**

- C1 / PanasonicBusiness. [**H.264 Compression Technology**](https://www.youtube.com/watch?v=PmoEsPWEdOA). 2013.
- C2 / [LiveVideoStack博客](https://blog.csdn.net/vn9PLgZvnPs1522s82g)
- C3 / Mickaël Raulet. [从HEVC到通用视频编码的下一代视频压缩技术](https://blog.csdn.net/vn9PLgZvnPs1522s82g/article/details/106152333)
- C4 / [雷霄骅博客](https://blog.csdn.net/leixiaohua1020)
